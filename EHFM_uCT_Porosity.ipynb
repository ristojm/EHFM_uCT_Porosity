{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import math as m\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import iqr, kurtosis, skew\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "#import pillow (PIL) to allow for image cropping\n",
    "import PIL \n",
    "from PIL import Image, ImageChops\n",
    "from io import BytesIO\n",
    "\n",
    "#image simplification and priming\n",
    "#Convolution libraries\n",
    "from scipy import signal\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.preprocessing import Binarizer\n",
    "#from sklearn.preprocessing import Binarizer\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "#Skimage used for direct detection ellipse\n",
    "from skimage import io\n",
    "from skimage import data, color, img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import hough_ellipse\n",
    "from skimage.draw import ellipse_perimeter\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "#Skimage used for direct detection circles\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "\n",
    "#OpenCV for circle detection\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define functions required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This allows for the cutting of black space from each uCT image\n",
    "def trim2(im,padding,offset):\n",
    "    #selecting the outermost pixels \n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, offset)\n",
    "    bbox = diff.getbbox()\n",
    "    #adding small boarder to each image \n",
    "    bbox = np.array(bbox).reshape(2,2)\n",
    "    bbox[0] -= padding\n",
    "    bbox[1] += padding\n",
    "    bbox = bbox.flatten()\n",
    "    bbox = tuple(bbox)\n",
    "    if bbox:\n",
    "        return bbox,padding\n",
    "\n",
    "#obscure convolutes 2D arrays with a (x,y) sized screen screen and then binarizes them\n",
    "def obscure(image_array,x,y,invert):\n",
    "    screen = np.ones((x,y), dtype=int) \n",
    "    image_array = signal.convolve2d(image_array,screen, mode='same') #,mode='same')\n",
    "    #convert image into binary\n",
    "    #image_array = np.where(image_array > 127.5, 1, 0)\n",
    "    if invert == 'yes':\n",
    "        image_array = np.where(image_array > 127.5, 0, 1)\n",
    "    elif invert == 'no':\n",
    "        image_array = np.where(image_array > 127.5, 1, 0)\n",
    "    return image_array\n",
    "\n",
    "#largestblob can be used to detect the largest region of connected pixels and returns a filled image of those pixels and an approximate radius of that region\n",
    "def largestblob(image_array,con):\n",
    "    ##first label connected regions of pixels of an integer array\n",
    "    #detect each areas with connected pixels \n",
    "    label_img, return_num = label(image_array,connectivity=con,return_num=True)\n",
    "    if return_num >= 1:\n",
    "        #calculate various statistics of each of the detected areas\n",
    "        props = regionprops(label_img)\n",
    "        #find the area in px of each of the detected areas\n",
    "        areas = [r.area for r in props]\n",
    "        #find the index of the largest areas\n",
    "        indexOfMax = np.argmax(areas)\n",
    "        #find the aproximate radius of the maximum area\n",
    "        blob_radius =  round(props[indexOfMax].major_axis_length/2)\n",
    "        blob = props[indexOfMax].filled_image\n",
    "        blob_loc = props[indexOfMax].centroid\n",
    "    else:\n",
    "        blob = 0\n",
    "        blob_radius = 0\n",
    "        blob_loc = (0,0)\n",
    "    return (blob,blob_radius,blob_loc)\n",
    "\n",
    "# #largestblob can be used to detect the largest region of connected pixels and returns a filled image of those pixels and an approximate radius of that region\n",
    "# def largestblob(image_array,con):\n",
    "#     ##first label connected regions of pixels of an integer array\n",
    "#     #detect each areas with connected pixels \n",
    "#     label_img, return_num = label(image_array,connectivity=con,return_num=True)\n",
    "#     if return_num >= 1:\n",
    "#         #calculate various statistics of each of the detected areas\n",
    "#         props = regionprops(label_img)\n",
    "#         #find the area in px of each of the detected areas\n",
    "#         areas = [r.area for r in props]\n",
    "#         #find the index of the largest areas\n",
    "#         indexOfMax = np.argmax(areas)\n",
    "#         #find the aproximate radius of the maximum area\n",
    "#         blob_radius =  round(props[indexOfMax].major_axis_length/2)\n",
    "#         blob = props[indexOfMax].filled_image\n",
    "#         blob_loc = props[indexOfMax].centroid\n",
    "#     else:\n",
    "#         blob = 0\n",
    "#         blob_radius = 0\n",
    "#         blob_loc = (0,0)\n",
    "#     return (blob,blob_radius,blob_loc)\n",
    "    \n",
    "        \n",
    "#This allows for the additon of a padding to numpy array - useful for adding boarders to images\n",
    "#found: https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 10)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initialisation of data read\n",
    "# #current location\n",
    "# location = os.getcwd()\n",
    "\n",
    "\n",
    "# #/Users/ristomartin/Dropbox/UniStuff/DPhil/Experimental/ES_PCL_PDO_270219/\n",
    "# #/Volumes/Seagate Backup Plus Drive/uCT/Reconstructed\n",
    "\n",
    "# #Python folder location\n",
    "# # loc = '/Users/ristomartin/dropbox/UniStuff/DPhil/Experimental/ES_PCL_PDO_270219/MicroCT/'#'/Volumes/Risto\\'s SSD/uCT/Reconstructed/'\n",
    "# #loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/hollow_fibre'\n",
    "\n",
    "\n",
    "# # loc = r'F:\\Alex_Witt\\uCT_Speed_Test\\Rec_Files'\n",
    "# #location for saved data\n",
    "# save_loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/hollow_fibre/output/'\n",
    "# # save_loc = r'C:\\Users\\Alex Witt\\Documents\\Python_Analysis\\Outputs'\n",
    "\n",
    "# #where is data in location\n",
    "# data_set = 'S4_10PPM_03_5PX_1_Rec'\n",
    "# data_loc = loc+'/'+data_set\n",
    "# #what to name to save files\n",
    "# #savename = '686cl_9do_5ppm_060619_Rec'\n",
    "# savename = data_set\n",
    "# # #key location\n",
    "# # key_loc = '/Users/ristomartin/Dropbox/UniStuff/DPhil/Experimental/ES_PCL_PDO_270219/sample_keys/'\n",
    "# # #key to use\n",
    "# # sample_key = key_loc + 'sample_key_130819.txt'\n",
    "# # #location of raw_porosity distributions\n",
    "# # raw_pore = '/Users/ristomartin/Dropbox/UniStuff/DPhil/Experimental/ES_PCL_PDO_270219/MicroCT/porosity_data/'\n",
    "\n",
    "# # #Import filename key - insert key location\n",
    "# # sample_key = pd.read_csv(sample_key,sep='\\t')\n",
    "\n",
    "# #initilisation of constants\n",
    "# #Set conversion of px to um\n",
    "# pxum = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Image processing script as function to be entered into multiprocessing\n",
    "def fibrefeature(dat_loc,filename,pxum,fibre_pad,fibre_scale,fibre1,wire_diameter,lumen_pad,trim_offset,reverse,lumen1,lumen2,lumen3,debug,debug_print,save_pic):\n",
    "    #check whether to save picture or not\n",
    "    save_pic = save_pic\n",
    "    #Intially open full image\n",
    "    im = Image.open(dat_loc+'/'+filename)\n",
    "    #check if file needs converting\n",
    "    if im.mode == 'I;16':\n",
    "        #specifying its sampling mode\n",
    "        im.mode = 'I'\n",
    "        #convert the mode into 'L' (8-bit pixels, black and white) and save as temporary file\n",
    "        im = im.point(lambda i:i*(1./256)).convert('L')\n",
    "        #open temporaray file\n",
    "        #im = Image.open('temp.jpeg')\n",
    "    elif im.mode == 'RGB' or im.mode == 'RGBA':\n",
    "        im = im.convert('L')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    #Once image is opened make copies of unedited image and array to use later on\n",
    "    #make copy of original unadultorated image\n",
    "    im_orig = im.copy()\n",
    "    #as well as an array of the unadultorated image\n",
    "    im_orig_array = np.array(im_orig)\n",
    "    #A = (A * B)\n",
    "    #im_orig_array = im_orig_array*(255.0/im_orig_array.max())\n",
    "    \n",
    "    im_orig_array = im_orig_array.astype(\"uint8\")\n",
    "    \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_orig_array, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'raw_image.png', dpi=300)\n",
    "            \n",
    "    ##Make selection of top RHS to find average pixel value to subtract\n",
    "    bg_x1 = round((0.80*im_orig_array.shape[1]))\n",
    "    bg_x2 = round((0.95*im_orig_array.shape[1]))\n",
    "    bg_y1 = round((0.5*im_orig_array.shape[0]))\n",
    "    bg_y2 = round((0.55*im_orig_array.shape[0]))\n",
    "    \n",
    "    bg_select = im_orig_array[bg_x1:bg_x2,bg_y1:bg_y2]\n",
    "    \n",
    "    # bg_select_df = pd.DataFrame(bg_select)\n",
    "    # bg_select_df.to_csv(save_loc+savename+'bg_select.csv')\n",
    "\n",
    "#     ret4,bg_select = cv2.threshold(im_orig_array,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(bg_select, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'_bg_select.png', dpi=300)\n",
    "    \n",
    "    height, width = bg_select.shape\n",
    "    bg_med = []\n",
    "    for i in range(0, width):\n",
    "        #temp = (bg_select[i,:] > 0.1) * bg_select[i,:]\n",
    "        temp = bg_select[i,:][bg_select[i,:]!=0]\n",
    "        bg_med.extend(temp)\n",
    "\n",
    "    #print(bg_med)\n",
    "    bg_select_med = np.median(bg_med)+2*np.std(bg_med)  \n",
    "    bg_select_mean = np.mean(bg_med)+2*np.std(bg_med)\n",
    "    \n",
    "    im_orig_array_c = im_orig_array.copy()\n",
    "    \n",
    "    #ret,bg_select = cv2.threshold(im_orig_array,bg_select_mean,im_orig_array.max(),cv2.THRESH_BINARY)\n",
    "    im_orig_array_c[im_orig_array_c < bg_select_mean] = 0\n",
    "    \n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_orig_array, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'_thresh_bg_select.png', dpi=300)\n",
    "            \n",
    "    im = Image.fromarray(im_orig_array_c)\n",
    "    \n",
    "    \n",
    "    im_debug = np.array(im)\n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_debug, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'im_debug.png', dpi=300)\n",
    "\n",
    "    #trim image to just pixels of interest using trim as defined above\n",
    "    fibre_box,fpadding = trim2(im,(fibre_pad*2),trim_offset)\n",
    "    im = im.crop(fibre_box)\n",
    "    #convert trimmed image into numpy array\n",
    "    nim =  np.array(im)\n",
    "    #make copy of trimmed image to be used later on if needed\n",
    "    nim_copy = nim.copy()\n",
    "    \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim_copy, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'cropped_image.png', dpi=300)\n",
    "            \n",
    "############################################################################################################################################################ \n",
    "                                                ### OUTER WALL DETECTION  ###\n",
    "############################################################################################################################################################\n",
    "    \n",
    "    ##-- priming image for further analysis with obscure as defined above\n",
    "    x = 7\n",
    "    y = 7\n",
    "    #Initially applying GayssuanBlur to minimise noise in image\n",
    "    nim = cv2.GaussianBlur(nim,(x,y),0)\n",
    "    #apply OTSU's binarisation method to strip away as much noise as possible and convert image into binary\n",
    "    ret,fibre_thresh = cv2.threshold(nim,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    x = 2\n",
    "    y = 2\n",
    "    #1. Mark all pixels such that there are at least 6 pixels in their 7x7 neighborhood this will become defined as obscure function\n",
    "    nim = signal.convolve2d(fibre_thresh,np.ones((x,y), dtype=int), mode='same')\n",
    "    \n",
    "    #Due to the porous nature of the hollow fibre membranes want to the dilate each of the detected regions into unified point\n",
    "#     x = 7\n",
    "#     y = 7\n",
    "#     kernel = np.ones((x,y), np.uint8)\n",
    "\n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'convolve2d_image.png', dpi=300)\n",
    "\n",
    "    change = int(fibre1*max(nim.shape))\n",
    "    if 1 > change:\n",
    "        change = 1\n",
    "    kernel = np.ones((change,change),np.uint8)\n",
    "    \n",
    "    nim = np.uint8(nim * 255)\n",
    "    nim = cv2.dilate(nim, kernel, iterations=1)\n",
    "    if trim_offset < -100:\n",
    "        nim = ndimage.binary_erosion(np.uint8(nim), structure=kernel,iterations =3).astype(nim.dtype)\n",
    "    else:\n",
    "        nim = ndimage.binary_erosion(np.uint8(nim), structure=kernel,iterations =2).astype(nim.dtype)\n",
    "    nim = ndimage.binary_dilation(nim,structure=kernel,iterations = 2).astype(nim.dtype)\n",
    "    \n",
    "\n",
    "    \n",
    "    nim = ndimage.binary_dilation(nim,structure=kernel,iterations = 1).astype(nim.dtype)\n",
    "    nim = ndimage.binary_erosion(np.uint8(nim), structure=kernel,iterations = 1).astype(nim.dtype)\n",
    "\n",
    "    \n",
    "    nim = np.uint8(nim * 255)\n",
    "    \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'pre_processed_image.png', dpi=300)\n",
    "\n",
    "        \n",
    "    #2. Remove all blobs, but the largest\n",
    "    dnim = rescale(nim, fibre_scale, anti_aliasing=False)\n",
    "    dnim = np.uint8(dnim * 255)\n",
    "\n",
    "    if debug == True:\n",
    "        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(dnim, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'resized_pre_processed_image.png', dpi=300)\n",
    "    \n",
    "    \n",
    "    #find largest blob in image\n",
    "    bww,fibre_radius,fibre_loc = largestblob(dnim,1)\n",
    "    \n",
    "    #rescale fibre radius and location from resizing\n",
    "    fibre_radius = fibre_radius/fibre_scale\n",
    "    fibre_loc = ((fibre_loc[0]/fibre_scale),(fibre_loc[1]/fibre_scale))\n",
    "    \n",
    "    if debug == True:\n",
    "        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(bww, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'first_largest_blob.png', dpi=300)\n",
    "            \n",
    "    #Padding\n",
    "    bww = np.pad(bww, [(fibre_pad, fibre_pad), (fibre_pad, fibre_pad)], mode='constant')\n",
    "    #nim_copy = np.pad(nim_copy, [(fibre_pad, fibre_pad), (fibre_pad, fibre_pad)], mode='constant')\n",
    "    \n",
    "    change = int(0.03*max(dnim.shape))\n",
    "    if 1 > change:\n",
    "        change = 1\n",
    "    kernel = np.ones((change,change),np.uint8)\n",
    "    \n",
    "    bww = ndimage.binary_dilation(bww,structure=kernel,iterations = 2).astype(bww.dtype)\n",
    "    \n",
    "    if debug == True:\n",
    "        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(bww, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'dilated_first_largest_blob.png', dpi=300)\n",
    "    \n",
    "    #bww = ndimage.binary_dilation(bww,structure=kernel,iterations = 1).astype(bww.dtype)\n",
    "    bww = ndimage.binary_erosion(np.uint8(bww), structure=kernel,iterations = 2).astype(dnim.dtype)\n",
    "    #bww = ndimage.binary_dilation(bww,structure=kernel,iterations = 1).astype(bww.dtype)\n",
    "    \n",
    "    if debug == True:\n",
    "        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(bww, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'erroded_first_largest_blob.png', dpi=300)\n",
    "    \n",
    "\n",
    "\n",
    "    bww = np.uint8(bww*255)\n",
    "       \n",
    "    bww = largestblob(bww,2)[0]\n",
    "    bww = np.pad(bww, [(fibre_pad, fibre_pad), (fibre_pad, fibre_pad)], mode='constant')\n",
    "\n",
    "    if debug == True:\n",
    "        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(bww, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'extracted_processed_first_largest_blob.png', dpi=300)\n",
    "    \n",
    "\n",
    "    #rescale image\n",
    "    bww = rescale(bww, 1/fibre_scale, anti_aliasing=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    #add boarder to numpy array of both the largest blob of connected pixels detected as well as the image used to detect them.\n",
    "    #want to add boarder as this allows for circles larger than the image to be drawn\n",
    "    if fibre_radius > 0:\n",
    "        #bww = np.pad(bww, [(fibre_pad, fibre_pad), (fibre_pad, fibre_pad)], mode='constant')\n",
    "        \n",
    "        if debug == True:\n",
    "            #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(bww, 'gray')\n",
    "            if save_pic == True:\n",
    "                ax.figure.savefig(save_loc+filename+'largest_blob.png', dpi=300)      \n",
    "\n",
    "\n",
    "        #3. Fill holes\n",
    "        #- this is not done as is auto in python\n",
    "\n",
    "        #4. Apply edge detection\n",
    "        #find edges in data\n",
    "        edges = canny(bww, sigma=3)\n",
    "        edges = np.uint8(edges * 255)\n",
    "        \n",
    "        if debug == True:\n",
    "            #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(edges, 'gray')\n",
    "            if save_pic == True:\n",
    "                ax.figure.savefig(save_loc+filename+'largest_blob_edges.png', dpi=300)   \n",
    "\n",
    "\n",
    "        #5. fit ellipse onto total fibre with cv2.fitellipse\n",
    "        #detect contours from edges\n",
    "        #for explination of hiarichy choice 'cv2.RETR_EXTERNAL' check:https://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "        #for explination of approximation choice 'cv2.CHAIN_APPROX_SIMPLE' check: https://docs.opencv.org/3.1.0/d3/dc0/group__imgproc__shape.html#ga4303f45752694956374734a03c54d5ff\n",
    "        contours = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "        #Select the external contours which collude to give the largest area to ensure outer points are taken\n",
    "        contours = max(contours, key=cv2.contourArea)\n",
    "        #print(contours)\n",
    "\n",
    "        #fit ellipse to contour points\n",
    "        #https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.html\n",
    "        #paper published on method used to find elipse https://pdfs.semanticscholar.org/19d9/becce00a500bdd1cad5a19f9f16175347096.pdf\n",
    "        (fibre_x,fibre_y),(FMA,fma),fangle = cv2.fitEllipse(contours)\n",
    "        FMA = int(FMA)\n",
    "        fma = int(fma)\n",
    "        fibre_x = int(fibre_x)\n",
    "        fibre_y = int(fibre_y)\n",
    "        faspect_ratio = FMA/fma\n",
    "\n",
    "        #first get the shape of the trimmed image\n",
    "        H, W = nim_copy.shape\n",
    "        image_diagonal = m.sqrt((H**2)+(W**2))\n",
    "\n",
    "        #put a check into the  ensure the detected ellipse is not larger than the image its self as this is a false detection            \n",
    "        if FMA < image_diagonal and fma < image_diagonal:\n",
    "            #draw ellipse onto edges\n",
    "            #having found the circle then plot the circle onto the image\n",
    "            image = edges\n",
    "            #convert the image into rgb to allow for plotting of red circle\n",
    "            image = color.gray2rgb(image)\n",
    "            #simiarly do this to the array of the array of the trimmed image\n",
    "            nim_copy_draw = color.gray2rgb(nim_copy)\n",
    "            \n",
    "            if debug == True:\n",
    "                #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                fig, ax = plt.subplots()\n",
    "                ax.imshow(nim_copy_draw, 'gray')\n",
    "                if save_pic == True:\n",
    "                    ax.figure.savefig(save_loc+filename+'nim_copy_draw.png', dpi=300)   \n",
    "\n",
    "\n",
    "\n",
    "            cv2.ellipse(image,((fibre_x,fibre_y),(FMA,fma),fangle),(0,0,255),2)\n",
    "            \n",
    "            cv2.ellipse(nim_copy_draw,((fibre_loc[1],fibre_loc[0]),(FMA,fma),fangle),(0,0,255),2)\n",
    "            \n",
    "            \n",
    "############################################################################################################################################################ \n",
    "                        ###IF NO ELLIPSE DETECTED TRY DETECT HOUGH CIRCLE###\n",
    "############################################################################################################################################################ \n",
    "            ellipse_fail = False\n",
    "        else:\n",
    "            ellipse_fail = True\n",
    "            if ellipse_fail==True:\n",
    "                pass\n",
    "            else:\n",
    "                print('hough')\n",
    "                #If incorrectly identify ellipse, try and detect with circle instead\n",
    "                #4.5 fit circle to detected edges \n",
    "                #As before can use the aproximate lumen radius to aproximate the size of the lumen\n",
    "                test_radii = np.flip(np.arange((fibre_radius-20), (fibre_radius+20), 1))\n",
    "                #print(test_radii)\n",
    "\n",
    "                #Using the approximate lumen size can then feed these into Hough filter to find regions of greatest interaction\n",
    "                hough_res = hough_circle(edges, test_radii)\n",
    "\n",
    "                # Select the most prominent circle\n",
    "                accums, fibre_x, fibre_y, FMA = hough_circle_peaks(hough_res,test_radii, min_xdistance=5, min_ydistance=5,  total_num_peaks=1)\n",
    "                #have the centrioid of the largest block detected within the image which is presumably and the centre of the blob image in the larger image\n",
    "                #fibre_x and fibre_y are the centroid of the ellipse or circle detected in the smaller image by finding the distance from the smaller image\n",
    "                #centroid can compute the adjustment add onto the larger image blob centroid to correctly position ellipse in larger image\n",
    "                foffset_x = (bww.shape[1]/2)-fibre_loc[1]\n",
    "                foffset_y = (bww.shape[0]/2)-fibre_loc[0]\n",
    "                #correcting \n",
    "                fibre_x = (fibre_x - foffset_x).astype(int)\n",
    "                fibre_y = (fibre_y - foffset_y).astype(int)\n",
    "                #print(type(FMA))\n",
    "                FMA = FMA.astype(int)\n",
    "\n",
    "                #having found the circle then plot the circle onto the image convert the image into rgb to allow for plotting of red circle\n",
    "                image = color.gray2rgb(edges)\n",
    "                #simiarly do this to the array of the array of the trimmed image\n",
    "                #print(type(nim_copy))\n",
    "                nim_copy_draw = color.gray2rgb(nim_copy)\n",
    "\n",
    "\n",
    "                #draw the circle from the hough circle detection onto both the edges diagram and trimmed image\n",
    "                for center_y, center_x, radius in zip(fibre_y, fibre_x, FMA):\n",
    "                    circy, circx = circle_perimeter(center_y, center_x, radius)\n",
    "                    image[circy, circx] = (220, 20, 20)\n",
    "                    nim_copy_draw[circy, circx] = (220, 20, 20)\n",
    "\n",
    "                if debug == True:\n",
    "                    #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.imshow(image, 'gray')\n",
    "                    if save_pic == True:\n",
    "                        ax.figure.savefig(save_loc+filename+'circle_on_edges.png', dpi=300)\n",
    "                    #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.imshow(nim_copy_draw, 'gray')\n",
    "                    if save_pic == True:\n",
    "                        ax.figure.savefig(save_loc+filename+'circle_on_image.png', dpi=300) \n",
    "\n",
    "\n",
    "                #make the minor fibre axis equal to that as major axis, as this is true of a circle\n",
    "                fma = FMA\n",
    "############################################################################################################################################################ \n",
    "                                                ### ISOLATION OF LUMEN ROI  ###\n",
    "############################################################################################################################################################\n",
    "\n",
    "\n",
    "        #check that if that the circle detected is not larger or less than 1/5th the size of the total image\n",
    "        if FMA < image_diagonal and (image_diagonal/10) < FMA:\n",
    "            if ellipse_fail == True:\n",
    "                pass\n",
    "            else:\n",
    "\n",
    "                ##-Having detected either a circle of ellipse use centre points to detect ROI\n",
    "                #Want to crop out only the region of interest\n",
    "                #To find the lumen of the fibre want can consider the central region of the detected fibre only as fibre will form around the wire\n",
    "                #set the size of the area of interest - as we are using a wire of 100um and the px size is ~1um use box width slightly larger to capture lumen\n",
    "                square_width = wire_diameter/pxum\n",
    "                #fibre_centre_x = center_x\n",
    "                #fibre_centre_y = center_y\n",
    "                x1 = int((fibre_loc[1])-(square_width/2))\n",
    "                y1 = int((fibre_loc[0])-(square_width/2))\n",
    "                x2 = int((fibre_loc[1])+(square_width/2))\n",
    "                y2 =int((fibre_loc[0])+(square_width/2))\n",
    "                square_nwc  = (x1,y1)\n",
    "                square_sec =(x2,y2)\n",
    "                \n",
    "                if debug_print == True:\n",
    "                    print('x1 ='+str(x1))\n",
    "                    print('y1 ='+str(y1))\n",
    "                    print('x2 ='+str(x2))\n",
    "                    print('y2 ='+str(y2))\n",
    "                \n",
    "                \n",
    "                #having defined the corners of the central region of the fibre can draw circle\n",
    "                #cv2.rectangle(image,(fibre_x-(square_width/2),fibre_y-(square_width/2)),(fibre_x+(square_width/2),fibre_y+(square_width/2)),(0,255,0),3)\n",
    "                cv2.rectangle(nim_copy_draw,(x1,y1),(x2,y2),(0,255,0),3)\n",
    "                \n",
    "                \n",
    "\n",
    "                if debug == True:\n",
    "                    #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.imshow(image, 'gray')\n",
    "                    if save_pic == True:\n",
    "                        ax.figure.savefig(save_loc+filename+'ellipse_on_edges.png', dpi=300)\n",
    "                    #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.imshow(nim_copy_draw, 'gray')\n",
    "                    if save_pic == True:\n",
    "                        ax.figure.savefig(save_loc+filename+'ellipse_on_image.png', dpi=300) \n",
    "\n",
    "\n",
    "\n",
    "                #Extracting ROI from image slice array\n",
    "                #having identified the outer circle and the central region within the image (where we should find the lumen) want to extract the region of interest\n",
    "                roi = nim_copy[y1:y2, x1:x2]\n",
    "\n",
    "                #check the shape of the roi extracted - if either is found to be 0 centre of detected region is off image and therefore an invalid fit\n",
    "                roi_H, roi_W = roi.shape\n",
    "                if roi_H != 0 or roi_W !=0:\n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(nim_copy_draw, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'image_with_roi_box.png', dpi=300)\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(roi, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'raw_ROI.png', dpi=300)\n",
    "\n",
    "\n",
    "    ############################################################################################################################################################ \n",
    "                                                    ### LUMEN DETECTION  ###\n",
    "    ############################################################################################################################################################\n",
    "\n",
    "                    #having extracted roi for lumen - want to peform similar transform as for entire image\n",
    "                    image_array = roi\n",
    "                    #apply thresholding using value calculated for total image before with OTSU's with inversed image as want to detect negitive space\n",
    "                    # ret2,image_array = cv2.threshold(image_array,ret,255,cv2.THRESH_BINARY_INV)\n",
    "                    \n",
    "                    #image_array, disc_array = cv2.threshold(roi,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                    \n",
    "                    ret2, image_array = cv2.threshold(image_array,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(image_array, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'pre_processing_lumen_image.png', dpi=300)\n",
    "                            \n",
    "                    change = int(lumen1*pxum*max(image_array.shape))\n",
    "                    if 1 > change:\n",
    "                        change = 1\n",
    "                    kernel = np.ones((change,change),np.uint8)\n",
    "                    \n",
    "                    if reverse == True:\n",
    "                        image_array = ndimage.binary_erosion(image_array, structure=kernel,iterations =4).astype(image_array.dtype)\n",
    "                    else:\n",
    "                        image_array = ndimage.binary_dilation(image_array,structure=kernel,iterations =4).astype(image_array.dtype)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(image_array, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'pre-erroded_lumen_image.png', dpi=300)\n",
    "\n",
    "\n",
    "                    x = 2\n",
    "                    y = 2\n",
    "                    #1. Mark all pixels such that there are at least 6 pixels in their 7x7 neighborhood this will become defined as obscure function\n",
    "                    #image_array = signal.convolve2d(image_array,np.ones((x,y), dtype=int), mode='same')\n",
    "                    image_array = np.uint8(image_array)\n",
    "                    \n",
    "                    ret2, image_array = cv2.threshold(image_array,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "                    \n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(image_array, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'convolved_lumen_image.png', dpi=300)\n",
    "                    #0.02\n",
    "                    change = int(lumen2*pxum**max(image_array.shape))\n",
    "                    if 1 > change:\n",
    "                        change = 1\n",
    "                    kernel = np.ones((change,change),np.uint8)\n",
    "                    \n",
    "                    #image_array = cv2.dilate(image_array, kernel, iterations=1)\n",
    "                    if reverse == True:\n",
    "                        image_array = ndimage.binary_erosion(image_array, structure=kernel,iterations = 2).astype(image_array.dtype)\n",
    "                    else:\n",
    "                        image_array = ndimage.binary_dilation(image_array,structure=kernel,iterations = 2).astype(image_array.dtype)\n",
    "                    \n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(image_array, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'initial_lumen_dilate.png', dpi=300)\n",
    "\n",
    "                    #0.015\n",
    "                    change = int(lumen3*pxum**max(image_array.shape))\n",
    "                    if 1 > change:\n",
    "                        change = 1\n",
    "                    kernel = np.ones((change,change),np.uint8)\n",
    "                    \n",
    "                    image_array = ndimage.binary_erosion(image_array, structure=kernel,iterations =2).astype(image_array.dtype)\n",
    "                    image_array = ndimage.binary_dilation(image_array,structure=kernel,iterations = 2).astype(image_array.dtype)\n",
    "                    \n",
    "                    \n",
    "#                     image_array = ndimage.binary_erosion(np.uint8(image_array), structure=kernel).astype(dnim.dtype)\n",
    "\n",
    "#                     image_array = cv2.dilate(image_array, kernel, iterations=1)\n",
    "\n",
    "                    image_array = cv2.threshold(image_array,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "                    #image_array = np.uint8(image_array * 255)\n",
    "\n",
    "                    #create plot of convoluted and binarised image\n",
    "                    if debug == True:\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(image_array, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'processed_lumen_image.png', dpi=300)\n",
    "\n",
    "\n",
    "                    # #2. Remove all blobs, but the largest\n",
    "                    # #downsize image\n",
    "                    # scale = 0.5\n",
    "                    # image_array = rescale(image_array, scale, anti_aliasing=False)\n",
    "                    # image_array = np.uint8(image_array * 255)\n",
    "\n",
    "                    # if debug == True:\n",
    "                    #     #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                    #     fig, ax = plt.subplots()\n",
    "                    #     ax.imshow(image_array, 'gray')\n",
    "                    #     if save_pic == True:\n",
    "                    #         ax.figure.savefig(save_loc+filename+'resized_pre_processed_lumen_image.png', dpi=300)\n",
    "\n",
    "\n",
    "                    #find largest blob in image\n",
    "                    lumen_blob,aprox_lumen_radius,lumen_blob_loc = largestblob(image_array,2)\n",
    "\n",
    "                    # #rescale fibre radius and location from resizing\n",
    "                    # lumen_radius = aprox_lumen_radius/scale\n",
    "                    # lumen_blob_loc = ((lumen_blob_loc[0]/scale),(lumen_blob_loc[1]/scale))\n",
    "\n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(image_array, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'first_largest_blob_lumen.png', dpi=300)                \n",
    "\n",
    "                    #Padding\n",
    "                    lumen_blob = np.pad(lumen_blob, [(fibre_pad, fibre_pad), (fibre_pad, fibre_pad)], mode='constant')\n",
    "\n",
    "                    #having padded the image take note of new size to allow for localisation of circles later on\n",
    "                    lumen_shape = lumen_blob.shape\n",
    "\n",
    "\n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(lumen_blob, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'ROI_largest_blob.png', dpi=300)\n",
    "\n",
    "\n",
    "                    #4. Apply edge detection\n",
    "                    #find edges in data\n",
    "                    lumen_edges = np.uint8(canny(lumen_blob, sigma=0.1)* 255)\n",
    "\n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(lumen_edges, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'ROI_edges.png', dpi=300)\n",
    "\n",
    "\n",
    "                    #5. Find circle using with cv2.fitellipse\n",
    "                    contours = cv2.findContours(lumen_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "                    #Select the external contours which collude to give the largest area to ensure outer points are taken\n",
    "                    contours = max(contours, key=cv2.contourArea)\n",
    "\n",
    "                    #fit ellipse to contour points\n",
    "                    #https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.html\n",
    "                    #paper published on method used to find elipse https://pdfs.semanticscholar.org/19d9/becce00a500bdd1cad5a19f9f16175347096.pdf\n",
    "                    (elumen_x,elumen_y),(LMA,lma),langle = cv2.fitEllipse(contours)\n",
    "                    LMA = int(LMA)\n",
    "                    lma = int(lma)\n",
    "                    elumen_x = int(elumen_x)\n",
    "                    elumen_y = int(elumen_y)\n",
    "                    laspect_ratio = LMA/lma\n",
    "\n",
    "                    #letting the detected edges of the lumen be background can now plot these as a check\n",
    "                    image = lumen_edges\n",
    "                    image = color.gray2rgb(image)\n",
    "\n",
    "                    #fit ellipse to contour points\n",
    "                    #https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.html\n",
    "                    #paper published on method used to find elipse https://pdfs.semanticscholar.org/19d9/becce00a500bdd1cad5a19f9f16175347096.pdf\n",
    "                    (elumen_x,elumen_y),(LMA,lma),langle = cv2.fitEllipse(contours)\n",
    "                    LMA = int(LMA)\n",
    "                    lma = int(lma)\n",
    "                    elumen_x = int(elumen_x)\n",
    "                    elumen_y = int(elumen_y)\n",
    "                    laspect_ratio = LMA/lma\n",
    "\n",
    "                    #letting the detected edges of the lumen be background can now plot these as a check\n",
    "                    image = lumen_edges\n",
    "                    image = color.gray2rgb(image)\n",
    "\n",
    "                    #draw ellipse onto edges\n",
    "                    cv2.ellipse(image,((elumen_x,elumen_y),(LMA,lma),langle),(0,0,255),2)\n",
    "\n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(image, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'ROI_ellipse.png', dpi=300)\n",
    "\n",
    "                    #Similarly transform centre of ROI detected by cv2.fitellipse\n",
    "                    #having found the parimeter of the lumen now want to plot back in orignial image\n",
    "\n",
    "\n",
    "                    lumen_plot_diffy = square_width - np.shape(lumen_edges)[0]\n",
    "                    lumen_plot_diffx = square_width - np.shape(lumen_edges)[1]\n",
    "\n",
    "                    #adjusting this for the larger image - add on the points from the origin of the roi within the larger image aka top left\n",
    "                    # print('square_width ='+str(square_width))\n",
    "                    # print('y2 ='+str(y2))\n",
    "                    # print('elumen_y ='+str(elumen_y))\n",
    "                    # print('lumen_plot_diffy ='+str(lumen_plot_diffy))\n",
    "                    # print('lumen_plot_diffx ='+str(lumen_plot_diffx))\n",
    "                    eroi_x1 = lumen_blob_loc[1]+x1\n",
    "                    eroi_y1 = lumen_blob_loc[0]+y1\n",
    "\n",
    "\n",
    "                    #cv2.ellipse(nim_copy_draw,((fibre_loc[1]+fibre_pad,fibre_loc[0]+fibre_pad),(FMA,fma),fangle),(0,0,255),2)\n",
    "\n",
    "                    #draw  the ellipse outline of the lumen onto the original image\n",
    "\n",
    "                    cv2.ellipse(nim_copy_draw,((lumen_blob_loc[1]+x1,lumen_blob_loc[0]+y1),(LMA,lma),langle),(0,0,255),2)\n",
    "                    #cv2.ellipse(nim_copy_draw,((eroi_x1,eroi_y1),(LMA,lma),langle),(0,0,255),2)\n",
    "\n",
    "                    if debug == True:\n",
    "                        #create plot of filled image of largest region of connected pixels within convoluted and binarised image\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.imshow(nim_copy_draw, 'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax.figure.savefig(save_loc+filename+'cropped_image_w_ROI.png', dpi=300)\n",
    "\n",
    "############################################################################################################################################################ \n",
    "                                        ### Determining porosity  ###\n",
    "############################################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "                    fibre_mask = np.zeros((nim_copy.shape[0],nim_copy.shape[1]))\n",
    "                    #print(FMA,fma)\n",
    "                    cv2.ellipse(fibre_mask,((((fibre_loc[1])),(fibre_loc[0])),(FMA,fma),fangle),255, -1)\n",
    "                    cv2.ellipse(fibre_mask,((eroi_x1,eroi_y1),(LMA,lma),langle),0,-1)\n",
    "\n",
    "                    #test to see if mask looks correct\n",
    "                    if debug == True:\n",
    "                        fig15, ax15 = plt.subplots()\n",
    "                        ax15.imshow(fibre_mask, cmap=plt.cm.gray)\n",
    "                        if save_pic == True:\n",
    "                            ax15.figure.savefig(save_loc+filename+'fibrepore_15.png', dpi=300)\n",
    "\n",
    "                    #creating masked image\n",
    "                    masked_image = np.where(fibre_mask == 255, nim_copy, 0)\n",
    "\n",
    "                    #test to see if mask is applied correctly\n",
    "                    if debug == True:\n",
    "                        fig16, ax16 = plt.subplots()\n",
    "                        ax16.imshow(masked_image, cmap=plt.cm.gray)\n",
    "                        if save_pic == True:\n",
    "                            ax16.figure.savefig(save_loc+filename+'fibrepore_16.png', dpi=300)\n",
    "\n",
    "\n",
    "                    # having produced a masked image of the region of interest want to binarize\n",
    "                    # Neither the adaptive thresholding methods appropriate as act more as edge detection rather than global binarization\n",
    "                    #to overcome the arbatory nature of global threshold use Otsu's method which detects the separtation in the pixel hiistogram to define cut off point\n",
    "                    #OTSU Threshold\n",
    "\n",
    "                    ret4,th5 = cv2.threshold(masked_image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                    if debug == True:\n",
    "                        fig17, ax17 = plt.subplots()\n",
    "                        ax17.imshow(th5,'gray')\n",
    "                        if save_pic == True:\n",
    "                            ax17.figure.savefig(save_loc+filename+'fibrepore_17.png', dpi=300)\n",
    "                    try:\n",
    "                        #Having converted into binary then look at ratio of pixels between white and black to get porosity\n",
    "                        mask_white_pxls = fibre_mask.sum()\n",
    "                        fibre_white_pxls = th5.sum()\n",
    "                        fibre_black_pxls = mask_white_pxls - fibre_white_pxls\n",
    "                        porosity = (fibre_black_pxls/mask_white_pxls)*100\n",
    "                        # print(porosity)\n",
    "\n",
    "############################################################################################################################################################ \n",
    "                                        ### Determining wall thickness  ###\n",
    "############################################################################################################################################################\n",
    "\n",
    "                        a = np.linspace(0,2*np.pi,num=100)\n",
    "                        rfangle = fangle * (np.pi/180)\n",
    "                        rfma = fma/2\n",
    "                        rFMA = FMA/2\n",
    "\n",
    "                        # fx = (rfma*np.cos(a)*np.cos(rfangle))-(rFMA*np.sin(a)*np.sin(rfangle))\n",
    "                        # fy = (rfma*np.cos(a)*np.sin(rfangle))+(rFMA*np.sin(a)*np.cos(rfangle))\n",
    "                        fx = (rFMA*np.cos(a)*np.cos(rfangle))-(rfma*np.sin(a)*np.sin(rfangle))\n",
    "                        fy = (rFMA*np.cos(a)*np.sin(rfangle))+(rfma*np.sin(a)*np.cos(rfangle))\n",
    "                        \n",
    "                        fr = [np.sqrt((fx[i]**2)+(fy[i]**2)) for i in range(len(fx))]# if fy[i]>0]\n",
    "                        f0 = [m.atan2(fy[i],fx[i]) for i in range(len(fx))]# if fy[i]>0]\n",
    "\n",
    "                        fd_df = pd.DataFrame()\n",
    "                        fd_df['fr'] = fr\n",
    "                        fd_df['f0'] = f0\n",
    "                        fd_df = fd_df.sort_values(by=['f0'], ascending=False)\n",
    "                        # print(fd_df.head())\n",
    "\n",
    "                        fr = fd_df['fr'].to_list()\n",
    "                        f0 = fd_df['f0'].to_list()\n",
    "\n",
    "                       # print(fr)\n",
    "                        #print(f0)\n",
    "                        # print('FMA='+str(FMA))\n",
    "                        # print('fma='+str(fma))\n",
    "\n",
    "                        rlangle = langle * (np.pi/180)\n",
    "                        rlma = lma/2\n",
    "                        rLMA = LMA/2\n",
    "                        # lx = (rlma*np.cos(a)*np.cos(rlangle))-(rLMA*np.sin(a)*np.sin(rlangle))-(fibre_loc[1]-eroi_x1)\n",
    "                        # ly = (rlma*np.cos(a)*np.sin(rlangle))+(rLMA*np.sin(a)*np.cos(rlangle))-(fibre_loc[0]-eroi_y1)\n",
    "                        lx = (rLMA*np.cos(a)*np.cos(rlangle))-(rlma*np.sin(a)*np.sin(rlangle))-(fibre_loc[1]-eroi_x1)\n",
    "                        ly = (rLMA*np.cos(a)*np.sin(rlangle))+(rlma*np.sin(a)*np.cos(rlangle))-(fibre_loc[0]-eroi_y1)\n",
    "\n",
    "                        lr = [np.sqrt((lx[i]**2)+(ly[i]**2)) for i in range(len(lx))]# if ly[i]>0]\n",
    "                        l0 = [m.atan2(ly[i],lx[i]) for i in range(len(lx))]# if ly[i]>0]\n",
    "\n",
    "                        ld_df = pd.DataFrame()\n",
    "                        ld_df['lr'] = lr\n",
    "                        ld_df['l0'] = l0\n",
    "                        #ld_df = ld_df.sort_values(by=['l0'], ascending=False)\n",
    "                        # print(ld_df.head())\n",
    "\n",
    "                        lr = ld_df['lr'].to_list()\n",
    "                        l0 = ld_df['l0'].to_list()\n",
    "                        #print(lr)\n",
    "                        #print(l0)\n",
    "\n",
    "                        if debug == True:\n",
    "                            #plot polar coordinates\n",
    "                            fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "                            ax.plot(l0, lr,'b')\n",
    "                            ax.plot(f0, fr,'r')\n",
    "                            if save_pic == True:\n",
    "                                ax.figure.savefig(save_loc+filename+'polar_output.png', dpi=300)\n",
    "\n",
    "                        # print(fr)\n",
    "                        # print(f0)\n",
    "                        # print(lr)\n",
    "                        # print(l0)\n",
    "\n",
    "                        distances = [np.sqrt(((fr[i]**2)+(lr[i]**2))-(2*fr[i]*lr[i]*np.cos(l0[i]-f0[i]))) for i in range(len(l0))]\n",
    "\n",
    "                        # print(distances)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        #find the minimum and maximum distance\n",
    "                        max_dis = np.amax(np.asarray(distances))\n",
    "                        min_dis = np.amin(np.asarray(distances))\n",
    "                        #find average \n",
    "                        wall_median = np.percentile(np.asarray(distances), 50)*pxum\n",
    "                        wall_mean = np.asarray(distances).mean()*pxum\n",
    "                        wall_skew = skew(np.asarray(distances))\n",
    "                        #from calculation of skew determine whether to use median or mean\n",
    "                        if abs(wall_skew) > 0.5:\n",
    "                            wall_stat = 'median'\n",
    "                        else:\n",
    "                            wall_stat = 'mean'\n",
    "\n",
    "############################################################################################################################################################ \n",
    "                                        ### Save out  ###\n",
    "############################################################################################################################################################\n",
    "\n",
    "                        return (porosity,max_dis,min_dis,wall_median,wall_mean,wall_skew,wall_stat,faspect_ratio,laspect_ratio)\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False\n",
    "show_all = True\n",
    "debug_print = False\n",
    "\n",
    "columns = ['porosity','max_dis','min_dis','wall_median','wall_mean','wall_skew','wall_stat','faspect_ratio','laspect_ratio']\n",
    "\n",
    "cfp = pd.DataFrame(columns = columns)\n",
    "\n",
    "if test == True:\n",
    "    \n",
    "    #where is data located    \n",
    "    #loc = '/Volumes/RISTO_EXHDD/Alex_Witt/uCT_Speed_Test/Rec_Files/'\n",
    "    loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/hollow_fibre'\n",
    "    # loc = '/Volumes/Ristos_SSD/uCT/ROIs/'\n",
    "    \n",
    "    #What is the name of the data set?\n",
    "    data_set = 'Test'#'S4_10PPM_03_5PX_1_Rec'\n",
    "    \n",
    "    data_loc = loc+'/'+data_set\n",
    "    \n",
    "    #location for saved data\n",
    "    save_loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/hollow_fibre/output/'\n",
    "    # save_loc = r'C:\\Users\\Alex Witt\\Documents\\Python_Analysis\\Outputs'\n",
    "    \n",
    "    #what to name to save files\n",
    "    savename = data_set\n",
    "\n",
    "    #initilisation of constants - Set conversion of px to um\n",
    "    pxum = 1\n",
    "    wire_diameter = 300\n",
    "    fibre_pad = 50\n",
    "    lumen_pad = 50\n",
    "    trim_offset = -80\n",
    "    \n",
    "    #Generate list of file in data location\n",
    "    files = [x for x in os.listdir(data_loc) if x.endswith(('.tif','.jpg','.png','.bmp'))==True and x.startswith('._')==False]\n",
    "    \n",
    "    #Itterating through files in data location\n",
    "    for filename in tqdm_notebook(files):\n",
    "        print(filename)\n",
    "        \n",
    "        #Lumen 1 - dilation\n",
    "        #Lumen 2 - errosion\n",
    "        #Lumen 3 - errosion then dilation\n",
    "        #acertain fibre properties as defined above\n",
    "        if show_all == True:\n",
    "            fibre_properties = fibrefeature(data_loc,filename,pxum,fibre_pad,0.25,0.05,wire_diameter,lumen_pad,trim_offset,False,0.01,0.3,0.3,True,True,True)\n",
    "        else:\n",
    "            fibre_properties = fibrefeature(data_loc,filename,pxum,fibre_pad,0.25,wire_diameter,lumen_pad,trim_offset,False,0.02,0.2,0.3,False,False,False)\n",
    "        if fibre_properties is None:\n",
    "            pass\n",
    "        else:\n",
    "            # print(fibre_properties)\n",
    "            print('porosity ='+str(fibre_properties[0]))\n",
    "            print('max_dis ='+str(fibre_properties[1]))\n",
    "            print('min_dis ='+str(fibre_properties[2]))\n",
    "            print('wall_median ='+str(fibre_properties[3]))\n",
    "            print('wall_mean ='+str(fibre_properties[4]))\n",
    "            print('wall_skew ='+str(fibre_properties[5]))\n",
    "            print('wall_stat ='+str(fibre_properties[6]))\n",
    "            print('faspect_ratio ='+str(fibre_properties[7]))\n",
    "            print('laspect_ratio ='+str(fibre_properties[8]))\n",
    "            cfp = cfp.append({'filename':filename,'porosity':fibre_properties[0],'max_dis':fibre_properties[1],'min_dis':fibre_properties[2],'wall_median':fibre_properties[3],\n",
    "                          'wall_mean':fibre_properties[4],'wall_skew':fibre_properties[5],'wall_stat':fibre_properties[6],'faspect_ratio':fibre_properties[7],\n",
    "                          'laspect_ratio':fibre_properties[8]}, ignore_index=True)\n",
    "    print(cfp.head())\n",
    "    cfp.to_csv(save_loc+savename+'.csv')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/7hyg5yn15331npl8_ss6cl_40000gn/T/ipykernel_9930/3928021706.py:42: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for filename in tqdm_notebook(files):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbf4cfa93bc4233ad2f6ce828ad5d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305cl_4do_5ppm_120619_rec_roi_0015.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0016.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0017.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0018.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0019.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0020.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0021.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0022.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0023.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0024.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0025.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0026.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0027.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0028.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0029.tif\n",
      "305cl_4do_5ppm_120619_rec_roi_0030.tif\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dw/7hyg5yn15331npl8_ss6cl_40000gn/T/ipykernel_9930/3928021706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#acertain fibre properties as defined above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mfibre_properties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfibrefeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpxum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfibre_pad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwire_diameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlumen_pad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrim_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfibre_properties\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dw/7hyg5yn15331npl8_ss6cl_40000gn/T/ipykernel_9930/4165197167.py\u001b[0m in \u001b[0;36mfibrefeature\u001b[0;34m(dat_loc, filename, pxum, fibre_pad, fibre_scale, fibre1, wire_diameter, lumen_pad, trim_offset, reverse, lumen1, lumen2, lumen3, debug, debug_print, save_pic)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mnim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_dilation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mnim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_erosion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/ndimage/morphology.py\u001b[0m in \u001b[0;36mbinary_dilation\u001b[0;34m(input, structure, iterations, mask, output, border_value, origin, brute_force)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0morigin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     return _binary_erosion(input, structure, iterations, mask,\n\u001b[0m\u001b[1;32m    519\u001b[0m                            output, border_value, origin, 1, brute_force)\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/ndimage/morphology.py\u001b[0m in \u001b[0;36m_binary_erosion\u001b[0;34m(input, structure, iterations, mask, output, border_value, origin, invert, brute_force)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         _nd_image.binary_erosion(input, structure, mask, output,\n\u001b[0m\u001b[1;32m    254\u001b[0m                                  border_value, origin, invert, cit, 0)\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Run = True\n",
    "\n",
    "columns = ['porosity','max_dis','min_dis','wall_median','wall_mean','wall_skew','wall_stat','faspect_ratio','laspect_ratio']\n",
    "\n",
    "cfp = pd.DataFrame(columns = columns)\n",
    "\n",
    "if Run == True:\n",
    "    \n",
    "    #where is data located    \n",
    "    #/Users/ristomartin/Dropbox/UniStuff/DPhil/Experimental/ES_PCL_PDO_270219/\n",
    "    #/Volumes/Seagate Backup Plus Drive/uCT/Reconstructed\n",
    "    #/Volumes/Risto's SSD/uCT/Reconstructed\n",
    "    #Python folder location\n",
    "    # loc = '/Users/ristomartin/dropbox/UniStuff/DPhil/Experimental/ES_PCL_PDO_270219/MicroCT/'#'/Volumes/Risto\\'s SSD/uCT/Reconstructed/'\n",
    "    #loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/hollow_fibre'\n",
    "    #loc = '/Volumes/RISTO_EXHDD/Alex_Witt/uCT_Speed_Test/Rec_Files/'\n",
    "    loc = '/Volumes/Ristos_SSD/uCT/ROIs/'\n",
    "\n",
    "    # loc = r'F:\\Alex_Witt\\uCT_Speed_Test\\Rec_Files'\n",
    "    #location for saved data\n",
    "    save_loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/hollow_fibre/output/'\n",
    "    # save_loc = r'C:\\Users\\Alex Witt\\Documents\\Python_Analysis\\Outputs'\n",
    "\n",
    "    #where is data in location\n",
    "    data_set = '305cl_4do_S1_5ppm_120619_Rec' #S4_10PPM_03_5PX_1_Rec\n",
    "    data_loc = loc+data_set\n",
    "    #what to name to save files\n",
    "    savename = data_set\n",
    "\n",
    "    #initilisation of constants - Set conversion of px to um\n",
    "    pxum = 1\n",
    "    wire_diameter = 300\n",
    "    fibre_pad = 50\n",
    "    lumen_pad = 50\n",
    "    trim_offset = -80\n",
    "    \n",
    "    \n",
    "    #Generate list of file in data location\n",
    "    files = [x for x in os.listdir(data_loc) if x.endswith(('.tif','.jpg','.png','.bmp'))==True and x.startswith('._')==False]\n",
    "    \n",
    "    #Itterating through files in data location\n",
    "    for filename in tqdm_notebook(files):\n",
    "        #print filename to track any error\n",
    "        print(filename)\n",
    "\n",
    "        #acertain fibre properties as defined above\n",
    "        fibre_properties = fibrefeature(data_loc,filename,pxum,fibre_pad,0.25,0.05,wire_diameter,lumen_pad,trim_offset,False,0.01,0.3,0.3,False,False,False)\n",
    "        if fibre_properties is None:\n",
    "            pass\n",
    "        else:        \n",
    "            cfp = cfp.append({'filename':filename,'porosity':fibre_properties[0],'max_dis':fibre_properties[1],'min_dis':fibre_properties[2],'wall_median':fibre_properties[3],\n",
    "                          'wall_mean':fibre_properties[4],'wall_skew':fibre_properties[5],'wall_stat':fibre_properties[6],'faspect_ratio':fibre_properties[7],\n",
    "                          'laspect_ratio':fibre_properties[8]}, ignore_index=True)\n",
    "    print(cfp.head())\n",
    "    cfp.to_csv(save_loc+savename+'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pore = save_loc+'MicroCT/porosity_data/'\n",
    "print(raw_pore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label each of the columns to be in final dataframe\n",
    "#uni_columns = ['fmajor_axis', 'fminor_axis', 'faspect_ratio', 'lmajor_axis', 'lminor_axis', 'laspect_ratio', 'porosity','fwall_mthickness']\n",
    "\n",
    "#create dataframe for all data\n",
    "cdf = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(raw_pore+'preprocessed/'):\n",
    "    #only open the file if it end with the specified parameters as specified in file name\n",
    "    if filename.endswith(\".csv\"):    \n",
    "        #reads the specified directory and opens it as a dataframe\n",
    "        df = pd.read_csv(os.path.join(raw_pore+'preprocessed/'+filename),index_col=0)\n",
    "        \n",
    "        #print(df.head())\n",
    "        \n",
    "        #Copy process parameters from sample key\n",
    "        df['Pyridine Concentration'] = sample_key.loc[sample_key['uCT_filename'] == filename, 'pyridine_conc'].iloc[0]\n",
    "        df['Wire Speed'] = sample_key.loc[sample_key['uCT_filename'] == filename, 'wire_speed'].iloc[0]\n",
    "        df['Rotation Speed'] = sample_key.loc[sample_key['uCT_filename'] == filename, 'rotation_speed'].iloc[0]\n",
    "        df['Polymer Solution'] = sample_key.loc[sample_key['uCT_filename'] == filename, 'solution_name'].iloc[0]\n",
    "        voltage = sample_key.loc[sample_key['uCT_filename'] == filename, 'voltage'].iloc[0]\n",
    "        min_voltage = sample_key.loc[sample_key['uCT_filename'] == filename, 'min_voltage'].iloc[0]\n",
    "        max_voltage = sample_key.loc[sample_key['uCT_filename'] == filename, 'max_voltage'].iloc[0]\n",
    "        df['Voltage Range'] = (((voltage-min_voltage)/(max_voltage-min_voltage))*100).round(0)\n",
    "        \n",
    "        #calculate maxiumum wall thickness\n",
    "        df['fwall_mthickness'] = (df['fmajor_axis'] - df['lminor_axis'])/2\n",
    "         \n",
    "        #concatonate all of the lists into a single massive list\n",
    "        cdf = pd.concat([df, cdf], axis=0,ignore_index=True,sort=False)\n",
    "#print(cdf.head())\n",
    "cdf.to_csv(save_loc+'MicroCT/porosity_data/processed/'+'cdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing fresh distributions to make summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeoutliers(dataframe):\n",
    "    Q1 = dataframe.quantile(0.25)\n",
    "    Q3 = dataframe.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    new_dataframe = dataframe[~((dataframe < (Q1 - 1.5 * IQR)) |(dataframe > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return new_dataframe\n",
    "\n",
    "def statskew(dataframe,property_column):\n",
    "    property_median = dataframe[property_column].median()\n",
    "    property_mean = dataframe[property_column].mean()\n",
    "    property_skew = skew(dataframe[property_column])\n",
    "    Q1 = dataframe[property_column].quantile(0.25)\n",
    "    Q3 = dataframe[property_column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    if abs(property_skew) > 0.5:\n",
    "        property = property_median\n",
    "    else:\n",
    "        property = property_mean\n",
    "    return property,IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification of distribution summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe for processed fibre properties\n",
    "columns = ['fmajor_axis', 'fminor_axis', 'faspect_ratio', 'lmajor_axis', 'lminor_axis', 'laspect_ratio', 'porosity']\n",
    "pfp = pd.DataFrame(columns = columns)\n",
    "\n",
    "#First copy all raw data file which you want to compare into a single file and then insert directory of file below\n",
    "#This then retreves the name of each file in the specified directory and cycle through them with the following\n",
    "for filename in os.listdir(raw_pore+'preprocessed/'):\n",
    "    #only open the file if it end with the specified parameters as specified in file name\n",
    "    if filename.endswith(\".csv\"):      \n",
    "        #reads the specified directory and opens it as a dataframe\n",
    "        df = pd.read_csv(os.path.join(raw_pore+'preprocessed/',filename))\n",
    "        \n",
    "        pore_min = df['porosity'].min()\n",
    "        pore_max = df['porosity'].max()\n",
    "        \n",
    "        #screening outliers from dataframe\n",
    "        sfp = removeoutliers(df)\n",
    "\n",
    "        #defining the statistical centre of each measured value - taking the statistical measure depending on skew\n",
    "        fmajor_axis,fmajor_IQR = statskew(sfp,'fmajor_axis')\n",
    "        fminor_axis,fminor_IQR = statskew(sfp,'fminor_axis')\n",
    "        faspect_ratio,faspect_IQR = statskew(sfp,'faspect_ratio')\n",
    "        lmajor_axis,lmajor_IQR = statskew(sfp,'lmajor_axis')\n",
    "        lminor_axis,lminor_IQR = statskew(sfp,'lminor_axis')\n",
    "        laspect_ratio,laspect_IQR = statskew(sfp,'laspect_ratio')\n",
    "        porosity,pore_IQR = statskew(sfp,'porosity')\n",
    "        fwall_mthickness = (fmajor_axis - lminor_axis)/2\n",
    "        fwall_mthickness_IQR = (fmajor_IQR + lminor_IQR)/2\n",
    "\n",
    "        #Import key fibre information\n",
    "        Pyridine_Concentration = sample_key.loc[sample_key['uCT_filename'] == filename, 'pyridine_conc'].iloc[0]\n",
    "        Wire_Speed = sample_key.loc[sample_key['uCT_filename'] == filename, 'wire_speed'].iloc[0]\n",
    "        Rotation_Speed = sample_key.loc[sample_key['uCT_filename'] == filename, 'rotation_speed'].iloc[0]\n",
    "        abs_pcl_conc = sample_key.loc[sample_key['uCT_filename'] == filename, 'abs_pcl_conc'].iloc[0]\n",
    "        abs_pdo_conc = sample_key.loc[sample_key['uCT_filename'] == filename, 'abs_pdo_conc'].iloc[0]\n",
    "        Polymer_Composition = ((abs_pcl_conc*100).round(2).astype(str) +'%PCL')+'\\n'+((abs_pdo_conc*100).round(2).astype(str) +'%PDO')\n",
    "        voltage = sample_key.loc[sample_key['uCT_filename'] == filename, 'voltage'].iloc[0]\n",
    "        min_voltage = sample_key.loc[sample_key['uCT_filename'] == filename, 'min_voltage'].iloc[0]\n",
    "        max_voltage = sample_key.loc[sample_key['uCT_filename'] == filename, 'max_voltage'].iloc[0]\n",
    "        Voltage_Range = (((voltage-min_voltage)/(max_voltage-min_voltage))*100).round(0)\n",
    "        \n",
    "        #append processed information \n",
    "        pfp = pfp.append({'fmajor_axis':fmajor_axis, 'fminor_axis':fminor_axis, 'faspect_ratio':faspect_ratio, \n",
    "                          'lmajor_axis':lmajor_axis, 'lminor_axis':lminor_axis, 'laspect_ratio':laspect_ratio, \n",
    "                          'porosity':porosity, 'Pyridine Concentration':Pyridine_Concentration,'Wire Speed':Wire_Speed, \n",
    "                          'Rotation Speed':Rotation_Speed,'Polymer Composition':Polymer_Composition,\n",
    "                          'Voltage Range': Voltage_Range,'pore_IQR':pore_IQR,'fmajor_IQR':fmajor_IQR,'fminor_IQR':fminor_IQR,\n",
    "                          'faspect_IQR':faspect_IQR,'lmajor_IQR':lmajor_IQR,'lminor_IQR':lminor_IQR,'laspect_IQR':laspect_IQR,\n",
    "                          'fwall_mthickness':fwall_mthickness,'fwall_mthickness_IQR':fwall_mthickness_IQR}, ignore_index=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "pfp.to_csv(save_loc+'MicroCT/porosity_data/processed/'+'all_processed'+'.csv')\n",
    "#print(pfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Want to consider the effect of each variable however as data is not filtered need to filter to evaluate the effect of only a single variable at a given time\n",
    "def varlayer(layer_num,layer_lst):\n",
    "    for layer_num in layer_lst:\n",
    "        #find all of the unique values of the 2nd controlled variable\n",
    "        uniquevalues = np.unique(grp2[layer_num].values)\n",
    "        for id in uniquevalues:\n",
    "            #create a dataframe which contains only fixed values of controlled variable 3\n",
    "            #create grp1 from variable in variable list\n",
    "            for key, nxtgrp in grp.groupby([layer_num]):\n",
    "                #To continue fixing the variable now shorten variable list to consider only other uncontrolled variables\n",
    "                nxt_layer_lst = layer_lst.copy() #list of secondary controlled variables\n",
    "                #removing x-axis variable so only consider changing variables\n",
    "                nxt_layer_lst.remove(layer_num)\n",
    "                return nxtgrp,nxt_layer_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first define variables to be quiried \n",
    "variables = ['Rotation Speed','Wire Speed','Pyridine Concentration','Polymer Solution','Voltage Range']\n",
    "#import summary data\n",
    "df = pd.read_csv(os.path.join(save_loc+'/'+'MicroCT'+'/'+'porosity_data'+'/'+'processed'+'/'+'cdf.csv'),index_col=0)\n",
    "\n",
    "#Filter summariesed data to isolate single variable effect\n",
    "for variable in variables:\n",
    "        #find all of the unique values of the 1st controlled variable\n",
    "        uniquevalues = np.unique(df[variable].values)\n",
    "        #for each of the different variables make dataframe further sub divided\n",
    "        for id1 in uniquevalues:\n",
    "            #create a dataframe which contains only fixed values of controlled variable 1\n",
    "            newdf1 = df[df[variable] == id1]\n",
    "            #To continue fixing the variable now shorten variable list to consider only other uncontrolled variables\n",
    "            #starting from x_hue\n",
    "            variable_lst2 = variables.copy() #list of secondary controlled variables\n",
    "            #removing x-axis variable so only consider changing variables\n",
    "            variable_lst2.remove(variable)\n",
    "            \n",
    "            for variable2 in variable_lst2:\n",
    "                #find all of the unique values of the 1st controlled variable\n",
    "                uniquevalues = np.unique(newdf1[variable2].values)\n",
    "                #for each of the different variables make dataframe further sub divided\n",
    "                for id2 in uniquevalues:\n",
    "                    #create a dataframe which contains only fixed values of controlled variable 2\n",
    "                    newdf2 = newdf1[newdf1[variable2] == id2]\n",
    "                    #To continue fixing the variable now shorten variable list to consider only other uncontrolled variables\n",
    "                    #starting from x_hue\n",
    "                    variable_lst3 = variable_lst2.copy() #list of secondary controlled variables\n",
    "                    #removing x-axis variable so only consider changing variables\n",
    "                    variable_lst3.remove(variable2)\n",
    "                    \n",
    "                    for variable3 in variable_lst3:\n",
    "                        #find all of the unique values of the 1st controlled variable\n",
    "                        uniquevalues = np.unique(newdf2[variable3].values)\n",
    "                        #for each of the different variables make dataframe further sub divided\n",
    "                        for id3 in uniquevalues:\n",
    "                            #create a dataframe which contains only fixed values of controlled variable 3\n",
    "                            newdf3 = newdf2[newdf2[variable3] == id3]\n",
    "                            #To continue fixing the variable now shorten variable list to consider only other uncontrolled variables\n",
    "                            #starting from x_hue\n",
    "                            variable_lst4 = variable_lst3.copy() #list of secondary controlled variables\n",
    "                            #removing x-axis variable so only consider changing variables\n",
    "                            variable_lst4.remove(variable3)\n",
    "                            \n",
    "                            for variable4 in variable_lst4:\n",
    "                                #starting from x_hue\n",
    "                                variable_lst4 = variable_lst3.copy() #list of secondary controlled variables\n",
    "                                #removing x-axis variable so only consider changing variables\n",
    "                                variable_lst4.remove(variable3)\n",
    "                                #find all of the unique values of the 1st controlled variable\n",
    "                                uniquevalues = np.unique(newdf3[variable4].values)\n",
    "                                #for each of the different variables make dataframe further sub divided\n",
    "                                \n",
    "                                for id4 in uniquevalues:\n",
    "                                    #starting from x_hue\n",
    "                                    variable_lst5 = variable_lst4.copy() #list of secondary controlled variables\n",
    "                                    #removing x-axis variable so only consider changing variables\n",
    "                                    variable_lst5.remove(variable4)\n",
    "                                    #create a dataframe which contains only fixed values of controlled variable 4\n",
    "                                    newdf4 = newdf3[newdf3[variable4] == id4]\n",
    "                                    \n",
    "                                    #In order to prevent duplications of files with same fixed variables but in different order\n",
    "                                    #make list of variables and order them\n",
    "                                    fxd_ivars = [str(id1),str(id2),str(id3),str(id4)]\n",
    "                                    fxd_ivars = sorted(fxd_ivars)\n",
    "                                                                        \n",
    "                                    #identify the different vaiables present to allow for potential statistical comparison\n",
    "                                    uniquevalues = np.unique(newdf4[variable_lst5[0]].values)\n",
    "\n",
    "                                    #create list of valuesvalues = []\n",
    "                                    values = []\n",
    "                                    #for each value remove PPM and convert to interger\n",
    "                                    for value in uniquevalues:\n",
    "                                        values.append(value)\n",
    "                                    #sort the list of values according to size\n",
    "                                    values.sort(reverse = False)\n",
    "                                    \n",
    "                                    \n",
    "                                    #if there are more than one variable continue to plot\n",
    "                                    if len(values) > 2:         \n",
    "\n",
    "                                        #Within the uncontrolled variable want to identify all the condidtions used\n",
    "                                        #uniquevalues = np.unique(newdf4[variable_lst5[0]].values)\n",
    "\n",
    "                                        #For each combination of the controlled variables want to evaluate how each metric changes\n",
    "                                        metrics = ['fmajor_axis','fminor_axis','faspect_ratio','lmajor_axis','lminor_axis',\n",
    "                                                   'laspect_ratio','porosity','fwall_mthickness']\n",
    "                                        #Evaluating the change in each of the metrics\n",
    "                                        for metric in metrics:\n",
    "                                            \n",
    "                                           \n",
    "                                            #for each oof the conditions used in the uncontrolled variable\n",
    "                                            for id5 in uniquevalues:\n",
    "                                                #To prevent duplication check if quiry has been made\n",
    "                                                if not os.path.isfile(save_loc+'/'+'MicroCT/'+'figures'+'/'+str(variable_lst5[0])+str(fxd_ivars)+metric+'.png'):\n",
    "                                                    #isolate the data associated for the same conditions used \n",
    "                                                    #newdf5 = newdf4[newdf4[variable_lst5[0]] == id5]\n",
    "                                                    \n",
    "                                                    \n",
    "                                                    #To be able to screen outliers with this method cannot have strings in table as these cannot be compared with >\n",
    "                                                    #For this reason have started to refer to different polymer solutions by numbers\n",
    "                                                    #screening outliers from dataframe\n",
    "                                                    #newdf4 = removeoutliers(newdf4,variable_lst5[0])\n",
    "                                                    #print(newdf4)\n",
    "                                                    Q1 = newdf4.quantile(0.25)\n",
    "                                                    #print(Q1)\n",
    "                                                    Q3 = newdf4.quantile(0.75)\n",
    "                                                    #print(Q3)\n",
    "                                                    IQR = Q3 - Q1\n",
    "                                                    newdf4 = newdf4[~((newdf4 < (Q1 - 1.5 * IQR)) |(newdf4 > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "                                                    #print(newdf4)\n",
    "                                                    #print(snewdf4)\n",
    "                                                    \n",
    "                                                    #Create new figure for each metric considered\n",
    "                                                    fig, ax = plt.subplots()\n",
    "                                                    \n",
    "                                                    #make scatter plot of data associated with each of the metrics\n",
    "                                                    #fig1 = ax.errorbar(newdf5[variable_lst5[0]], newdf5[metric], fmt='o',label=label)\n",
    "                                                    fig = sns.violinplot(x= newdf4[variable_lst5[0]], y= newdf4[metric], showfliers=True, order= values,ax=ax)\n",
    "                                                    #to account for solutions being refered to by number now must extract number from figure\n",
    "                                                    if variable_lst5[0] == 'Polymer Solution':\n",
    "                                                        polysolkey = {'0.0':'Trial','1.0':'Initial' ,'2.0':'S1','3.0':'S2',\n",
    "                                                                      '4.0':'S3','5.0':'S4','6.0':'S5'}\n",
    "                                                        labels = [t.get_text()  for t in ax.get_xticklabels()]\n",
    "                                                    #    print(labels)\n",
    "                                                        new_labels = [polysolkey[l] for l in labels]\n",
    "                                                    #    print(new_labels)\n",
    "                                                        fig.set_xticklabels(new_labels)\n",
    "\n",
    "                                                    #before can add statistical annotation must create boxPairList from previous statistical comparison table\n",
    "                                                    #create list for boxpairlist\n",
    "                                                    pre_boxPairList = []\n",
    "\n",
    "\n",
    "                                                    #for count of number of o values\n",
    "                                                    for index in range(len(values)):\n",
    "                                                        #to ensure that all combinations are considered again copy the uniquevalues\n",
    "                                                        avalues = values.copy() #colour hue\n",
    "                                                        #removing fixed variable so only consider changing variables\n",
    "                                                        avalues.remove(values[index])\n",
    "                                                        #considereing the appending value\n",
    "                                                        for index in range(len(avalues)):\n",
    "                                                            #let a = the file name and the ovalue which corresponds to the number within the list and pair them\n",
    "                                                            a = (avalues[index],values[index])\n",
    "                                                            #add the pair to the list of boxed pairs\n",
    "                                                            if avalues[index] != values[index]:\n",
    "                                                                if a not in pre_boxPairList:\n",
    "                                                                    pre_boxPairList.append(a)\n",
    "                                                            else: pass\n",
    "                                                    #pre_boxPairList = sorted(pre_boxPairList)\n",
    "                                                    #print(pre_boxPairList)\n",
    "\n",
    "                                                    #add statistical annotations\n",
    "                                                    add_stat_annotation(x= newdf4[variable_lst5[0]], y= newdf4[metric],order= values,showfliers=True,\n",
    "                                                                        boxPairList=pre_boxPairList,test='Mann-Whitney', textFormat='star', loc='inside', verbose=0,\n",
    "                                                                        ax=ax)\n",
    "\n",
    "                                                    #label axis\n",
    "                                                    #create dictionary of y-axis labels associated with each of the metrics\n",
    "                                                    y_lables = {'fmajor_axis':'Maximum Fibre Diameter ($\\mu$m)','fminor_axis':'Minimum Fibre Diameter ($\\mu$m)',\n",
    "                                                                'faspect_ratio':'Fibre Aspect Ratio','lmajor_axis':'Maximum Lumen Diameter ($\\mu$m)',\n",
    "                                                                'lminor_axis':'Minimum Lumen Diameter ($\\mu$m)','laspect_ratio':'Lumen Aspect Ratio',\n",
    "                                                                'porosity':'Porosity (%)','fwall_mthickness':'Maximum Fibre Wall thickness'}\n",
    "\n",
    "                                                    x_lables = {'Polymer Composition':'Polymer Composition','Pyridine Concentration':'Pyridine Concentration (PPM)',\n",
    "                                                               'Polymer Solution':'Polymer Solution'}\n",
    "\n",
    "                                                    ax.set_ylabel(y_lables[metric])\n",
    "                                                    ax.set_xlabel(x_lables[variable_lst5[0]])\n",
    "\n",
    "                                                    #bx_data = [bx_q1,bx_med,bx_q3]\n",
    "\n",
    "                                                    #ax = sns.boxplot(data=bx_data)\n",
    "\n",
    "                                                    #after looping through all of the catagories, save figure\n",
    "                                                    ax.figure.savefig(save_loc+'/'+'MicroCT/'+'figures'+'/'+str(variable_lst5[0])+str(fxd_ivars)+metric+'.png',bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Summary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first define variables to be quiried \n",
    "variables = ['Rotation Speed','Wire Speed','Pyridine Concentration','Polymer Composition','Voltage Range']\n",
    "#import summary data\n",
    "df = pd.read_csv(os.path.join(save_loc+'/'+'MicroCT'+'/'+'porosity_data'+'/'+'processed'+'/'+'all_processed.csv'))\n",
    "                   \n",
    "#Filter summariesed data to isolate single variable effect\n",
    "for variable in variables:\n",
    "        #find all of the unique values of the 1st controlled variable\n",
    "        uniquevalues = np.unique(df[variable].values)\n",
    "        #for each of the different variables make dataframe further sub divided\n",
    "        for id1 in uniquevalues:\n",
    "            #create a dataframe which contains only fixed values of controlled variable 1\n",
    "            newdf1 = df[df[variable] == id1]\n",
    "            #To continue fixing the variable now shorten variable list to consider only other uncontrolled variables\n",
    "            #starting from x_hue\n",
    "            variable_lst2 = variables.copy() #list of secondary controlled variables\n",
    "            #removing x-axis variable so only consider changing variables\n",
    "            variable_lst2.remove(variable)\n",
    "            \n",
    "            for variable2 in variable_lst2:\n",
    "                #find all of the unique values of the 1st controlled variable\n",
    "                uniquevalues = np.unique(newdf1[variable2].values)\n",
    "                #for each of the different variables make dataframe further sub divided\n",
    "                for id2 in uniquevalues:\n",
    "                    #create a dataframe which contains only fixed values of controlled variable 2\n",
    "                    newdf2 = newdf1[newdf1[variable2] == id2]\n",
    "                    #To continue fixing the variable now shorten variable list to consider only other uncontrolled variables\n",
    "                    #starting from x_hue\n",
    "                    variable_lst3 = variable_lst2.copy() #list of secondary controlled variables\n",
    "                    #removing x-axis variable so only consider changing variables\n",
    "                    variable_lst3.remove(variable2)\n",
    "                    \n",
    "                    for variable3 in variable_lst3:\n",
    "                        #find all of the unique values of the 1st controlled variable\n",
    "                        uniquevalues = np.unique(newdf2[variable3].values)\n",
    "                        #for each of the different variables make dataframe further sub divided\n",
    "                        for id3 in uniquevalues:\n",
    "                            #create a dataframe which contains only fixed values of controlled variable 3\n",
    "                            newdf3 = newdf2[newdf2[variable3] == id3]\n",
    "                            #To continue fixing the variable now shorten variable list to consider only other uncontrolled variables\n",
    "                            #starting from x_hue\n",
    "                            variable_lst4 = variable_lst3.copy() #list of secondary controlled variables\n",
    "                            #removing x-axis variable so only consider changing variables\n",
    "                            variable_lst4.remove(variable3)\n",
    "                            \n",
    "                            for variable4 in variable_lst4:\n",
    "                                #starting from x_hue\n",
    "                                variable_lst4 = variable_lst3.copy() #list of secondary controlled variables\n",
    "                                #removing x-axis variable so only consider changing variables\n",
    "                                variable_lst4.remove(variable3)\n",
    "                                #find all of the unique values of the 1st controlled variable\n",
    "                                uniquevalues = np.unique(newdf3[variable4].values)\n",
    "                                #for each of the different variables make dataframe further sub divided\n",
    "                                \n",
    "                                for id4 in uniquevalues:\n",
    "                                    #starting from x_hue\n",
    "                                    variable_lst5 = variable_lst4.copy() #list of secondary controlled variables\n",
    "                                    #removing x-axis variable so only consider changing variables\n",
    "                                    variable_lst5.remove(variable4)\n",
    "                                    #create a dataframe which contains only fixed values of controlled variable 4\n",
    "                                    newdf4 = newdf3[newdf3[variable4] == id4]\n",
    "                                    \n",
    "                                    #save the new dataframe as a csv - to be compared later on\n",
    "                                    #In order to prevent duplications of files with same fixed variables but in different order\n",
    "                                    #make list of variables and order them\n",
    "                                    fxd_ivars = [str(id1),str(id2),str(id3),str(id4)]\n",
    "                                    fxd_ivars = sorted(fxd_ivars)\n",
    "                                    \n",
    "                                    #To prevent duplication check if quiry has been made\n",
    "                                    if not os.path.isfile(save_loc+'/'+'MicroCT/'+'figures'+'/'+str(variable_lst5[0])+str(fxd_ivars)+metric+'.png'):\n",
    "                                        \n",
    "                                        #identify the different vaiables present to allow for potential statistical comparison\n",
    "                                        uniquevalues = np.unique(newdf4[variable_lst5[0]].values)\n",
    "                                        \n",
    "                                        #create list of values\n",
    "                                        values = []\n",
    "                                        #for each value remove PPM and convert to interger\n",
    "                                        for value in uniquevalues:\n",
    "                                            values.append(value)\n",
    "                                        #sort the list of values according to size\n",
    "                                        values.sort(reverse = True)\n",
    "\n",
    "                                        #before can add statistical annotation must create boxPairList from previous statistical comparison table\n",
    "                                        #create list for boxpairlist\n",
    "                                        pre_boxPairList = []\n",
    "\n",
    "\n",
    "                                        #for count of number of o values\n",
    "                                        for index in range(len(values)):\n",
    "                                            #to ensure that all combinations are considered again copy the uniquevalues\n",
    "                                            avalues = values.copy() #colour hue\n",
    "                                            #removing fixed variable so only consider changing variables\n",
    "                                            avalues.remove(values[index])\n",
    "                                            #considereing the appending value\n",
    "                                            for index in range(len(avalues)):\n",
    "                                                #let a = the file name and the ovalue which corresponds to the number within the list and pair them\n",
    "                                                a = (avalues[index],values[index])\n",
    "                                                #add the pair to the list of boxed pairs\n",
    "                                                if avalues[index] != values[index]:\n",
    "                                                    if a not in pre_boxPairList:\n",
    "                                                        pre_boxPairList.append(a)\n",
    "                                                else: pass\n",
    "                                        #pre_boxPairList = sorted(pre_boxPairList)\n",
    "                                        #print(pre_boxPairList)\n",
    "                                        \n",
    "                                        #if there are more than one variable continue to plot\n",
    "                                        if len(pre_boxPairList) > 1:\n",
    "                                            \n",
    "                                            #Within the uncontrolled variable want to identify all the condidtions used\n",
    "                                            uniquevalues = np.unique(newdf4[variable_lst5[0]].values)\n",
    "                                            \n",
    "                                            #For each combination of the controlled variables want to evaluate how each metric changes\n",
    "                                            metrics = ['fmajor_axis','fminor_axis','faspect_ratio','lmajor_axis','lminor_axis',\n",
    "                                                       'laspect_ratio','porosity','fwall_mthickness']\n",
    "                                            #Evaluating the change in each of the metrics\n",
    "                                            for metric in metrics:\n",
    "                                                #Create new figure for each metric considered\n",
    "                                                fig, ax = plt.subplots()\n",
    "                                                #for each oof the conditions used in the uncontrolled variable\n",
    "                                                for id5 in uniquevalues:\n",
    "                                                    #isolate the data associated for the same conditions used \n",
    "                                                    newdf5 = newdf4[newdf4[variable_lst5[0]] == id5]\n",
    "                                                    \n",
    "                                                    #create dictionary of IQRs associated with each of the metrics\n",
    "                                                    IQRs = {'fmajor_axis':'fmajor_IQR','fminor_axis':'fminor_IQR','faspect_ratio':'faspect_IQR',\n",
    "                                                            'lmajor_axis':'lmajor_IQR','lminor_axis':'lminor_IQR','laspect_ratio':'laspect_IQR',\n",
    "                                                            'porosity':'pore_IQR','fwall_mthickness':'fwall_mthickness_IQR'}\n",
    "                                                    \n",
    "                                                    #make scatter plot of data associated with each of the metrics\n",
    "                                                    fig1 = ax.errorbar(newdf5[variable_lst5[0]], newdf5[metric], yerr=newdf5[IQRs[metric]], fmt='o',label=label)\n",
    "                                                    \n",
    "                                                    #label axis\n",
    "                                                    #create dictionary of y-axis labels associated with each of the metrics\n",
    "                                                    y_lables = {'fmajor_axis':'Maximum Fibre Diameter ($\\mu$m)','fminor_axis':'Minimum Fibre Diameter ($\\mu$m)',\n",
    "                                                                'faspect_ratio':'Fibre Aspect Ratio','lmajor_axis':'Maximum Lumen Diameter ($\\mu$m)',\n",
    "                                                                'lminor_axis':'Minimum Lumen Diameter ($\\mu$m)','laspect_ratio':'Lumen Aspect Ratio',\n",
    "                                                                'porosity':'Porosity (%)','fwall_mthickness':'Maximum Fibre Wall thickness'}\n",
    "                                                    \n",
    "                                                    x_lables = {'Polymer Composition':'Polymer Composition','Pyridine Concentration':'Pyridine Concentration (PPM)'}\n",
    "\n",
    "                                                    ax.set_ylabel(y_lables[metric])\n",
    "                                                    ax.set_xlabel(x_lables[variable_lst5[0]])\n",
    "\n",
    "                                                    bx_data = [bx_q1,bx_med,bx_q3]\n",
    "\n",
    "                                                    #ax = sns.boxplot(data=bx_data)\n",
    "\n",
    "                                                #after looping through all of the catagories, save figure\n",
    "                                                ax.figure.savefig(save_loc+'/'+'MicroCT/'+'figures'+'/'+str(variable_lst5[0])+str(fxd_ivars)+metric+'.png',bbox_inches='tight', dpi=300)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
